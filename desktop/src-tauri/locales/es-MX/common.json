{
	"aborting": "Abortando",
	"advanced": "Avanzado",
	"app-title": "Vibe",
	"ask-for-download-model": "¿Te gustaría descargar el modelo desde el sitio web?",
	"ask-for-install-ytdlp-message": "¿Te gustaría instalar ytdlp, el cual es usado para descargar audio de sitios web populares?",
	"ask-for-install-ytdlp-title": "Instalar ytdlp",
	"ask-for-relaunch-body": "¿Te gustaría relanzar la applicación ahora?",
	"ask-for-relaunch-title": "Actualización finalizada",
	"ask-for-update-body": "¿Quieres actualizar vibe a la version {{version}}?",
	"ask-for-update-title": "Confirmar actualización",
	"cancel": "Cancelar",
	"cancel-relaunch": "Después",
	"cancel-update": "Después",
	"change-file": "Cambiar archivo",
	"change-files": "Cambiar archivos",
	"change-models-folder": "Cambiar el directorio de los modelos",
	"characters": "caracteres",
	"check-error": "La verificación falló",
	"check-loading": "Verificando",
	"check-success": "Probado con éxito",
	"confirm-exit": "¿Quieres salir? \nLos cambios no guardados se perderán.",
	"confirm-relaunch": "Relanzar Ahora",
	"confirm-update": "Actualizar Ahora",
	"copied": "¡Copiado!",
	"copy": "Copiar",
	"copy-logs": "Copiar Registros",
	"custom-ffmpeg-command": "Comando personalizado",
	"customize": "Personalizar",
	"customize-info": "Descarga cualquier modelo soportado en formato ggml o gguf (con la extensión del archivo terminando en '.bin'). Transfiérelo al directorio de los modelos, posteriormente seleccionalo del menú desplegable. No es necesario reiniciar 🌟",
	"dark": "Oscuro",
	"diarize-threshold": "Umbral de reconocimiento del hablante",
	"discord-community": "Comunidad de Discord",
	"download-file": "Descargar y transcribir",
	"download-model": "Descargar modelo",
	"download-models-link": "Descargar Modelos",
	"downloading-ai-models": "Descargando modelos de IA...",
	"downloading-model": "Descargando Modelo de OpenAI...",
	"downloading-ytdlp": "Descargando ytdlp",
	"enable-logs": "Habilitar Registros",
	"error": "Error",
	"error-title": "Error",
	"ffmpeg-options": "Opciones de FFMPEG",
	"files": "Archivos",
	"find-here": "Encontrar aquí",
	"focus-window-on-finish": "Enfocar ventana",
	"format": "Formato",
	"formats": "Formatos",
	"general": "General",
	"gpu-device": "Número del dispositivo GPU",
	"high-gpu-performance": "Establecer el rendimiento de gráficos a alto",
	"i-prefer-manual-setup": "Prefiero descargar manualmente",
	"info-cancel-download": "Puedes cancelar y descargar el modelo manualmente después.",
	"info-diarize-threshold": "Umbral de reconocimiento del hablante o considerar como no detectado",
	"info-enable-logs": "Escribir registros al archivo. Por favor reinicia al habilitarlo.",
	"info-gpu-device": "Selecciona el dispositivo GPU para la transcripción. Introduce el número del dispositivo GPU, empezando desde 0. Si tienes dos GPUs, elige ya sea 0 o 1.",
	"info-high-gpu-performance": "Mejora el rendimiento gráfico de Vibe, pero consumirá más recursos del sistema.",
	"info-llm-api-key": "La clave API del sitio web del modelo de IA.",
	"info-llm-prompt": "Prompt para el modelo de AI. Debe incluir el patrón %s el cual será reemplazado durante la transcripción.",
	"info-llm-summarize": "Resume con AI. Requiere clave API. Una vez que la transcripción se complete, será enviada a la API de Claude junto con el prompt elegido y tras unos segundos la respuesta de la IA será mostrada en Vibe en lugar de la transcripción. ¡También funciona cuando se transcriben múltiples archivos!",
	"info-manual-download": "Se requiere de una conexión a internet para descargar el modelo de IA",
	"info-max-sentence-len": "¿Cuantas letras estarán en un enunciado. Funciona solo cuando la marca de tiempo está activada.",
	"info-max-speakers": "¿Cuántos hablantes debería de haber en el archivo? Se usa para un reconocimiento más preciso",
	"info-max-text-ctx": "Tokens de contexto máximos a usar del texto pasado como un prompt para el decodificador",
	"info-max-tokens": "Máximo de tokens para el modelo de IA. Cada token se considera normalmente como una sola palabra. Esto puede ahorrarle el envío de demasiados datos, que cuestan dinero. Se recomienda restringirlo también en el sitio web.",
	"info-normalize-loudness": "Habilite esta opción para una mejor precisión de la transcripción. \nPuede tardar hasta 8 minutos por hora de audio.",
	"info-prompt": "Mejore las transcripciones escribiendo las palabras esperadas.",
	"info-recognize-speakers": "Detectar el hablante en cada frase y añadirlo",
	"info-temperature": "Valores más altos conducen a palabras más únicas; los valores más bajos se ciñen a las comunes. Suele fijarse en torno a 0.4 para obtener un resultado equilibrado.",
	"info-threads": "Aumente el uso de CPU para una descodificación más rápida; equilibre la velocidad con el uso de recursos. Recomendado: 4",
	"info-translate-to-english": "Traduzca la transcripción al inglés desde cualquier idioma activando esta opción",
	"info-use-word-timestamps": "Transcripción con marcas de tiempo de palabras en lugar de marcas de tiempo de frases. Útil en formato JSON. Desactivado cuando el reconocimiento del hablante está activado.",
	"install-now": "Instalar Ahora",
	"invalid-llm-prompt": "Prompt inválido. Debe incluir el siguiente patrón %s que será reemplazado con la transcripción.",
	"language": "Idioma",
	"leftover": "sobrante",
	"light": "Claro",
	"llm-api-key": "Clave API de Claude",
	"llm-current-cost": "Costos de uso",
	"llm-model": "Modelo",
	"llm-platform": "Platforma",
	"llm-prompt": "Prompt",
	"logs-folder": "Directorio de registros",
	"max-sentence-len": "Máxima longitud de enunciado",
	"max-speakers": "Hablantes máximos",
	"max-text-ctx": "Contexto máximo",
	"max-tokens": "Tokens Máximos",
	"microphone": "Micrófono",
	"modal-close": "Cerrar",
	"modal-error-body": "¡Un bug ocurrió!",
	"mode-text": "Texto",
	"model-options": "Opciones del Modelo",
	"models-folder": "Directorio de Modelos",
	"more-options": "Más Opciones",
	"no-connection": "Sin Conexión",
	"no-record": "Ninguno",
	"normalize-loudness": "Normalizar el volumen",
	"ollama-base-url": "URL de Ollama",
	"others": "Otros",
	"paste-model-link": "Pegar Enlace del Modelo",
	"play-sound-on-finish": "Reproducir sonido",
	"popular": "Popular",
	"print-tooltip": "Imprimir",
	"process-with-llm": "Resumir",
	"project-link": "Acerca de Vibe",
	"prompt": "Prompt",
	"recognize-speakers": "Reconocer hablantes",
	"record": "Grabar",
	"replace-all": "Reemplazar Todos",
	"report-issue": "Reportar Problema",
	"reset-app": "Reiniciar Vibe",
	"reset-ask-dialog": "¿Estás seguro(a) de que quieres reiniciar vibe? La información de la aplicación se limpiará incluyendo los archivos de los modelos.",
	"right-alignment": "Alineación derecha",
	"run-llm-check": "Verificar",
	"save-record-in-documents-folder": "Guardar el archivo de audio en los documentos",
	"save-success": "¡Guardado exitoso!",
	"save-transcript": "Guardar transcripción",
	"segments-tab": "Transcripción",
	"select-file": "Seleccionar Archivo",
	"select-language": "Seleccionar Idioma",
	"select-model": "Seleccionar Modelo",
	"select-theme": "Seleccionar Tema",
	"set-monthly-spend-limit": "Establecer límite de gasto mensual",
	"settings": "Configuración",
	"speaker-prefix": "Hablante",
	"speaker-recognition": "Reconocimiento del Hablante",
	"speakers": "Hablantes",
	"start-record": "Guardar y transcribir",
	"stop-and-transcribe": "Detener guardado",
	"summarize-loading": "resumiendo",
	"summarize-success": "Resumido",
	"summary-tab": "Resumen",
	"support-the-project": "Apoyar Vibe",
	"temp-folder": "Archivos temporales",
	"temperature": "Temperatura",
	"theme": "Tema",
	"this-happens-once": "¡Esto solo sucede una vez! 🎉",
	"threads": "Procesos",
	"transcribe": "Transcribir",
	"transcribe-took": "Transcripción exitosa en {{total}} segundos.",
	"transcribed": "Transcrito",
	"transcribing": "Transcribiendo...",
	"transcript-will-displayed-shortly": "La transcripción se mostrará aquí en breve...",
	"translate-to-english": "Traducir a Inglés",
	"try-again": "Intenta de nuevo",
	"update-version": "Actualizar Vibe",
	"updating-modal-body": "Actualizando Vibe a la version {{version}}",
	"updating-modal-title": "Actualizando...",
	"use-word-timestamps": "Marcas de tiempo por cada palabra",
	"when-completing-transcription": "Cuando se complete la transcripción"
}
